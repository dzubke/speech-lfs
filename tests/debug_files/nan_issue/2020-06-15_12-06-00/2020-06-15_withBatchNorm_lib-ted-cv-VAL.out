nohup: ignoring input
/home/dzubke/miniconda3/envs/awni_env36/lib/python3.6/site-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'speech.models.ctc_model_train.CTC_train' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.
  warnings.warn(msg, SourceChangeWarning)
  0%|          | 0/96139 [00:00<?, ?it/s]Succesfully loaded weights from trained model
====== Model, loaders, optimimzer created =======
model: CTC_train(
  (conv): Sequential(
    (0): Conv2d(1, 32, kernel_size=(11, 41), stride=(1, 2), padding=(0, 20))
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Dropout(p=0.4)
    (4): Conv2d(32, 32, kernel_size=(11, 21), stride=(1, 2), padding=(0, 10))
    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): ReLU()
    (7): Dropout(p=0.4)
    (8): Conv2d(32, 96, kernel_size=(11, 21), stride=(1, 1), padding=(0, 10))
    (9): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): ReLU()
    (11): Dropout(p=0.4)
  )
  (rnn): LSTM(6240, 512, num_layers=5, batch_first=True, dropout=0.4)
  (fc): LinearND(
    (fc): Linear(in_features=512, out_features=40, bias=True)
  )
)
preproc: Showing limited attributes as not all new attributes are supported

_input_dim: 257
start_and_end: False
int_to_char: {0: 'zh', 1: 'p', 2: 'v', 3: 'l', 4: 'uh', 5: 'k', 6: 'oy', 7: 'd', 8: 'jh', 9: 'ae', 10: 'ih', 11: 'z', 12: 'ey', 13: 'er', 14: 'eh', 15: 'ao', 16: 'r', 17: 'ay', 18: 'iy', 19: 'm', 20: 'ah', 21: 'uw', 22: 'th', 23: 'g', 24: 'y', 25: 'f', 26: 'n', 27: 'sh', 28: 's', 29: 'b', 30: 'dh', 31: 'ow', 32: 'aw', 33: 't', 34: 'hh', 35: 'aa', 36: 'w', 37: 'ch', 38: 'ng'}
char_to_int: {'zh': 0, 'p': 1, 'v': 2, 'l': 3, 'uh': 4, 'k': 5, 'oy': 6, 'd': 7, 'jh': 8, 'ae': 9, 'ih': 10, 'z': 11, 'ey': 12, 'er': 13, 'eh': 14, 'ao': 15, 'r': 16, 'ay': 17, 'iy': 18, 'm': 19, 'ah': 20, 'uw': 21, 'th': 22, 'g': 23, 'y': 24, 'f': 25, 'n': 26, 'sh': 27, 's': 28, 'b': 29, 'dh': 30, 'ow': 31, 'aw': 32, 't': 33, 'hh': 34, 'aa': 35, 'w': 36, 'ch': 37, 'ng': 38}
optimizer: SGD (
Parameter Group 0
    dampening: 0.98
    initial_lr: 0.0008
    lr: 0.0008
    momentum: 0.9
    nesterov: False
    weight_decay: 0
)
learning rate: 0.0008
  0%|          | 0/96139 [00:09<?, ?it/s, avg_loss=3.58, data_time=8.07, grad_norm=559, iter=0, loss=358, model_time=1.14]  0%|          | 1/96139 [00:09<246:14:14,  9.22s/it, avg_loss=3.58, data_time=8.07, grad_norm=559, iter=0, loss=358, model_time=1.14]  0%|          | 1/96139 [00:09<246:14:14,  9.22s/it, avg_loss=4.07, data_time=8.09, grad_norm=116, iter=1, loss=52.5, model_time=1.43]  0%|          | 2/96139 [00:09<174:49:10,  6.55s/it, avg_loss=4.07, data_time=8.09, grad_norm=116, iter=1, loss=52.5, model_time=1.43]  0%|          | 2/96139 [00:09<174:49:10,  6.55s/it, avg_loss=5.36, data_time=8.13, grad_norm=240, iter=2, loss=132, model_time=1.82]   0%|          | 3/96139 [00:09<125:52:36,  4.71s/it, avg_loss=5.36, data_time=8.13, grad_norm=240, iter=2, loss=132, model_time=1.82]  0%|          | 3/96139 [00:10<125:52:36,  4.71s/it, avg_loss=8.04, data_time=8.16, grad_norm=776, iter=3, loss=274, model_time=2.62]  0%|          | 4/96139 [00:10<94:43:55,  3.55s/it, avg_loss=8.04, data_time=8.16, grad_norm=776, iter=3, loss=274, model_time=2.62]   0%|          | 4/96139 [00:19<94:43:55,  3.55s/it, avg_loss=16.2, data_time=14.8, grad_norm=8.89e+3, iter=4, loss=826, model_time=4.58]  0%|          | 5/96139 [00:19<135:26:44,  5.07s/it, avg_loss=16.2, data_time=14.8, grad_norm=8.89e+3, iter=4, loss=826, model_time=4.58]  0%|          | 5/96139 [00:21<135:26:44,  5.07s/it, avg_loss=24.5, data_time=14.9, grad_norm=9.33e+3, iter=5, loss=847, model_time=6.24]  0%|          | 6/96139 [00:21<108:33:38,  4.07s/it, avg_loss=24.5, data_time=14.9, grad_norm=9.33e+3, iter=5, loss=847, model_time=6.24]  0%|          | 6/96139 [00:22<108:33:38,  4.07s/it, avg_loss=33.6, data_time=14.9, grad_norm=1.14e+4, iter=6, loss=930, model_time=7.88]  0%|          | 7/96139 [00:22<89:28:49,  3.35s/it, avg_loss=33.6, data_time=14.9, grad_norm=1.14e+4, iter=6, loss=930, model_time=7.88]   0%|          | 7/96139 [00:23<89:28:49,  3.35s/it, avg_loss=35.9, data_time=15, grad_norm=6.21e+3, iter=7, loss=267, model_time=8.32]    0%|          | 8/96139 [00:23<66:22:08,  2.49s/it, avg_loss=35.9, data_time=15, grad_norm=6.21e+3, iter=7, loss=267, model_time=8.32]  0%|          | 8/96139 [00:24<66:22:08,  2.49s/it, avg_loss=43, data_time=15.5, grad_norm=7.1e+4, iter=8, loss=743, model_time=9.38]   0%|          | 9/96139 [00:24<59:04:28,  2.21s/it, avg_loss=43, data_time=15.5, grad_norm=7.1e+4, iter=8, loss=743, model_time=9.38]  0%|          | 9/96139 [00:25<59:04:28,  2.21s/it, avg_loss=50.8, data_time=15.5, grad_norm=2.19e+4, iter=9, loss=829, model_time=10.5]  0%|          | 10/96139 [00:25<50:22:00,  1.89s/it, avg_loss=50.8, data_time=15.5, grad_norm=2.19e+4, iter=9, loss=829, model_time=10.5]  0%|          | 10/96139 [00:27<50:22:00,  1.89s/it, avg_loss=58.4, data_time=15.6, grad_norm=3.92e+3, iter=10, loss=812, model_time=11.5]  0%|          | 11/96139 [00:27<43:36:10,  1.63s/it, avg_loss=58.4, data_time=15.6, grad_norm=3.92e+3, iter=10, loss=812, model_time=11.5]  0%|          | 11/96139 [00:27<43:36:10,  1.63s/it, avg_loss=59.9, data_time=15.6, grad_norm=1.07e+3, iter=11, loss=201, model_time=11.8]  0%|          | 12/96139 [00:27<33:16:45,  1.25s/it, avg_loss=59.9, data_time=15.6, grad_norm=1.07e+3, iter=11, loss=201, model_time=11.8]  0%|          | 12/96139 [00:34<33:16:45,  1.25s/it, avg_loss=75.2, data_time=21.5, grad_norm=3.85e+4, iter=12, loss=1.59e+3, model_time=13.5]  0%|          | 13/96139 [00:34<84:11:46,  3.15s/it, avg_loss=75.2, data_time=21.5, grad_norm=3.85e+4, iter=12, loss=1.59e+3, model_time=13.5]  0%|          | 13/96139 [00:35<84:11:46,  3.15s/it, avg_loss=79.1, data_time=21.5, grad_norm=6.74e+4, iter=13, loss=467, model_time=14]        0%|          | 14/96139 [00:35<63:49:35,  2.39s/it, avg_loss=79.1, data_time=21.5, grad_norm=6.74e+4, iter=13, loss=467, model_time=14]  0%|          | 14/96139 [00:36<63:49:35,  2.39s/it, avg_loss=83.7, data_time=21.6, grad_norm=2.76e+4, iter=14, loss=538, model_time=14.7]  0%|          | 15/96139 [00:36<49:57:30,  1.87s/it, avg_loss=83.7, data_time=21.6, grad_norm=2.76e+4, iter=14, loss=538, model_time=14.7]  0%|          | 15/96139 [00:36<49:57:30,  1.87s/it, avg_loss=86.2, data_time=21.6, grad_norm=1.05e+3, iter=15, loss=335, model_time=15.1]  0%|          | 16/96139 [00:36<38:17:05,  1.43s/it, avg_loss=86.2, data_time=21.6, grad_norm=1.05e+3, iter=15, loss=335, model_time=15.1]  0%|          | 16/96139 [00:44<38:17:05,  1.43s/it, avg_loss=101, data_time=28.1, grad_norm=2.77e+8, iter=16, loss=1.58e+3, model_time=16.7]  0%|          | 17/96139 [00:44<92:02:24,  3.45s/it, avg_loss=101, data_time=28.1, grad_norm=2.77e+8, iter=16, loss=1.58e+3, model_time=16.7]  0%|          | 17/96139 [00:45<92:02:24,  3.45s/it, avg_loss=111, data_time=28.2, grad_norm=5.22e+5, iter=17, loss=1.05e+3, model_time=17.7]  0%|          | 18/96139 [00:45<73:28:12,  2.75s/it, avg_loss=111, data_time=28.2, grad_norm=5.22e+5, iter=17, loss=1.05e+3, model_time=17.7]  0%|          | 18/96139 [00:46<73:28:12,  2.75s/it, avg_loss=119, data_time=28.2, grad_norm=2.42e+4, iter=18, loss=941, model_time=18.7]      0%|          | 19/96139 [00:46<59:14:31,  2.22s/it, avg_loss=119, data_time=28.2, grad_norm=2.42e+4, iter=18, loss=941, model_time=18.7]  0%|          | 19/96139 [00:48<59:14:31,  2.22s/it, avg_loss=135, data_time=28.2, grad_norm=3.77e+7, iter=19, loss=1.75e+3, model_time=20.3]  0%|          | 20/96139 [00:48<54:32:47,  2.04s/it, avg_loss=135, data_time=28.2, grad_norm=3.77e+7, iter=19, loss=1.75e+3, model_time=20.3]  0%|          | 20/96139 [00:53<54:32:47,  2.04s/it, avg_loss=153, data_time=31.2, grad_norm=2.98e+11, iter=20, loss=1.92e+3, model_time=22.2]  0%|          | 21/96139 [00:53<76:59:40,  2.88s/it, avg_loss=153, data_time=31.2, grad_norm=2.98e+11, iter=20, loss=1.92e+3, model_time=22.2]  0%|          | 21/96139 [00:54<76:59:40,  2.88s/it, avg_loss=166, data_time=31.3, grad_norm=4.72e+8, iter=21, loss=1.45e+3, model_time=23.6]   0%|          | 22/96139 [00:54<65:30:15,  2.45s/it, avg_loss=166, data_time=31.3, grad_norm=4.72e+8, iter=21, loss=1.45e+3, model_time=23.6]  0%|          | 22/96139 [00:56<65:30:15,  2.45s/it, avg_loss=183, data_time=31.3, grad_norm=8.5e+9, iter=22, loss=1.86e+3, model_time=25.3]   0%|          | 23/96139 [00:56<60:23:02,  2.26s/it, avg_loss=183, data_time=31.3, grad_norm=8.5e+9, iter=22, loss=1.86e+3, model_time=25.3]  0%|          | 23/96139 [00:57<60:23:02,  2.26s/it, avg_loss=186, data_time=31.4, grad_norm=1.98e+5, iter=23, loss=515, model_time=25.9]     0%|          | 24/96139 [00:57<46:54:54,  1.76s/it, avg_loss=186, data_time=31.4, grad_norm=1.98e+5, iter=23, loss=515, model_time=25.9]  0%|          | 24/96139 [00:57<46:54:54,  1.76s/it, avg_loss=188, data_time=31.4, grad_norm=8.82e+3, iter=24, loss=407, model_time=26.3]  0%|          | 25/96139 [00:57<36:44:34,  1.38s/it, avg_loss=188, data_time=31.4, grad_norm=8.82e+3, iter=24, loss=407, model_time=26.3]  0%|          | 25/96139 [00:58<36:44:34,  1.38s/it, avg_loss=196, data_time=31.4, grad_norm=3.95e+9, iter=25, loss=989, model_time=27.3]  0%|          | 26/96139 [00:58<33:51:23,  1.27s/it, avg_loss=196, data_time=31.4, grad_norm=3.95e+9, iter=25, loss=989, model_time=27.3]  0%|          | 26/96139 [00:59<33:51:23,  1.27s/it, avg_loss=204, data_time=31.5, grad_norm=9.1e+5, iter=26, loss=933, model_time=28.2]   0%|          | 27/96139 [00:59<32:10:43,  1.21s/it, avg_loss=204, data_time=31.5, grad_norm=9.1e+5, iter=26, loss=933, model_time=28.2]  0%|          | 27/96139 [01:01<32:10:43,  1.21s/it, avg_loss=221, data_time=31.7, grad_norm=6.38e+8, iter=27, loss=1.93e+3, model_time=30.1]  0%|          | 28/96139 [01:01<38:04:59,  1.43s/it, avg_loss=221, data_time=31.7, grad_norm=6.38e+8, iter=27, loss=1.93e+3, model_time=30.1]  0%|          | 28/96139 [01:07<38:04:59,  1.43s/it, avg_loss=234, data_time=35.9, grad_norm=1.37e+9, iter=28, loss=1.46e+3, model_time=31.5]  0%|          | 29/96139 [01:07<72:36:28,  2.72s/it, avg_loss=234, data_time=35.9, grad_norm=1.37e+9, iter=28, loss=1.46e+3, model_time=31.5]  0%|          | 29/96139 [01:08<72:36:28,  2.72s/it, avg_loss=245, data_time=36, grad_norm=8.28e+5, iter=29, loss=1.36e+3, model_time=32.9]    0%|          | 30/96139 [01:08<62:02:33,  2.32s/it, avg_loss=245, data_time=36, grad_norm=8.28e+5, iter=29, loss=1.36e+3, model_time=32.9]  0%|          | 30/96139 [01:09<62:02:33,  2.32s/it, avg_loss=247, data_time=36, grad_norm=7.98e+3, iter=30, loss=428, model_time=33.3]      0%|          | 31/96139 [01:09<47:15:29,  1.77s/it, avg_loss=247, data_time=36, grad_norm=7.98e+3, iter=30, loss=428, model_time=33.3]  0%|          | 31/96139 [01:10<47:15:29,  1.77s/it, avg_loss=259, data_time=36.1, grad_norm=1.76e+9, iter=31, loss=1.53e+3, model_time=34.8]  0%|          | 32/96139 [01:10<45:31:40,  1.71s/it, avg_loss=259, data_time=36.1, grad_norm=1.76e+9, iter=31, loss=1.53e+3, model_time=34.8]  0%|          | 32/96139 [01:13<45:31:40,  1.71s/it, avg_loss=265, data_time=37.7, grad_norm=6.99e+3, iter=32, loss=834, model_time=35.6]      0%|          | 33/96139 [01:13<51:37:48,  1.93s/it, avg_loss=265, data_time=37.7, grad_norm=6.99e+3, iter=32, loss=834, model_time=35.6]  0%|          | 33/96139 [01:16<51:37:48,  1.93s/it, avg_loss=281, data_time=39.2, grad_norm=2.33e+13, iter=33, loss=1.82e+3, model_time=37.5]  0%|          | 34/96139 [01:16<62:32:47,  2.34s/it, avg_loss=281, data_time=39.2, grad_norm=2.33e+13, iter=33, loss=1.82e+3, model_time=37.5]  0%|          | 34/96139 [01:17<62:32:47,  2.34s/it, avg_loss=282, data_time=39.2, grad_norm=1.4e+4, iter=34, loss=446, model_time=38]          0%|          | 35/96139 [01:17<47:42:46,  1.79s/it, avg_loss=282, data_time=39.2, grad_norm=1.4e+4, iter=34, loss=446, model_time=38]  0%|          | 35/96139 [01:17<47:42:46,  1.79s/it, avg_loss=286, data_time=39.2, grad_norm=5.43e+4, iter=35, loss=667, model_time=38.7]  0%|          | 36/96139 [01:17<39:27:32,  1.48s/it, avg_loss=286, data_time=39.2, grad_norm=5.43e+4, iter=35, loss=667, model_time=38.7]  0%|          | 36/96139 [01:21<39:27:32,  1.48s/it, avg_loss=293, data_time=41.8, grad_norm=6.4e+4, iter=36, loss=1e+3, model_time=39.7]  0%|          | 37/96139 [01:21<56:28:11,  2.12s/it, avg_loss=293, data_time=41.8, grad_norm=6.4e+4, iter=36, loss=1e+3, model_time=39.7]  0%|          | 37/96139 [01:21<56:28:11,  2.12s/it, avg_loss=294, data_time=41.8, grad_norm=1.29e+3, iter=37, loss=374, model_time=40.2]  0%|          | 38/96139 [01:21<43:17:06,  1.62s/it, avg_loss=294, data_time=41.8, grad_norm=1.29e+3, iter=37, loss=374, model_time=40.2]  0%|          | 38/96139 [01:23<43:17:06,  1.62s/it, avg_loss=308, data_time=41.9, grad_norm=1.41e+5, iter=38, loss=1.66e+3, model_time=41.9]  0%|          | 39/96139 [01:23<44:17:41,  1.66s/it, avg_loss=308, data_time=41.9, grad_norm=1.41e+5, iter=38, loss=1.66e+3, model_time=41.9]  0%|          | 39/96139 [01:24<44:17:41,  1.66s/it, avg_loss=310, data_time=42.3, grad_norm=7.44e+5, iter=39, loss=507, model_time=42.4]      0%|          | 40/96139 [01:24<39:05:46,  1.46s/it, avg_loss=310, data_time=42.3, grad_norm=7.44e+5, iter=39, loss=507, model_time=42.4]  0%|          | 40/96139 [01:32<39:05:46,  1.46s/it, avg_loss=325, data_time=48.1, grad_norm=7.65e+8, iter=40, loss=1.87e+3, model_time=44.4]  0%|          | 41/96139 [01:32<89:39:49,  3.36s/it, avg_loss=325, data_time=48.1, grad_norm=7.65e+8, iter=40, loss=1.87e+3, model_time=44.4]  0%|          | 41/96139 [01:33<89:39:49,  3.36s/it, avg_loss=327, data_time=48.2, grad_norm=4.6e+4, iter=41, loss=527, model_time=45]         0%|          | 42/96139 [01:33<67:50:14,  2.54s/it, avg_loss=327, data_time=48.2, grad_norm=4.6e+4, iter=41, loss=527, model_time=45]  0%|          | 42/96139 [01:35<67:50:14,  2.54s/it, avg_loss=342, data_time=48.2, grad_norm=5.19e+5, iter=42, loss=1.74e+3, model_time=46.9]  0%|          | 43/96139 [01:35<63:12:13,  2.37s/it, avg_loss=342, data_time=48.2, grad_norm=5.19e+5, iter=42, loss=1.74e+3, model_time=46.9]  0%|          | 43/96139 [01:36<63:12:13,  2.37s/it, avg_loss=354, data_time=48.3, grad_norm=3.67e+10, iter=43, loss=1.54e+3, model_time=48.6]  0%|          | 44/96139 [01:36<58:16:07,  2.18s/it, avg_loss=354, data_time=48.3, grad_norm=3.67e+10, iter=43, loss=1.54e+3, model_time=48.6]  0%|          | 44/96139 [01:38<58:16:07,  2.18s/it, avg_loss=356, data_time=49.1, grad_norm=2.7e+4, iter=44, loss=598, model_time=49.2]        0%|          | 45/96139 [01:38<51:55:43,  1.95s/it, avg_loss=356, data_time=49.1, grad_norm=2.7e+4, iter=44, loss=598, model_time=49.2]  0%|          | 45/96139 [01:38<51:55:43,  1.95s/it, avg_loss=357, data_time=49.1, grad_norm=9.79e+3, iter=45, loss=411, model_time=49.7]  0%|          | 46/96139 [01:38<40:50:03,  1.53s/it, avg_loss=357, data_time=49.1, grad_norm=9.79e+3, iter=45, loss=411, model_time=49.7]  0%|          | 46/96139 [01:39<40:50:03,  1.53s/it, avg_loss=356, data_time=49.1, grad_norm=1.16e+3, iter=46, loss=315, model_time=50.1]  0%|          | 47/96139 [01:39<31:56:09,  1.20s/it, avg_loss=356, data_time=49.1, grad_norm=1.16e+3, iter=46, loss=315, model_time=50.1]  0%|          | 47/96139 [01:43<31:56:09,  1.20s/it, avg_loss=364, data_time=52.3, grad_norm=2.27e+5, iter=47, loss=1.19e+3, model_time=51.4]  0%|          | 48/96139 [01:43<58:37:08,  2.20s/it, avg_loss=364, data_time=52.3, grad_norm=2.27e+5, iter=47, loss=1.19e+3, model_time=51.4]  0%|          | 48/96139 [01:45<58:37:08,  2.20s/it, avg_loss=371, data_time=53.2, grad_norm=6.03e+3, iter=48, loss=1.06e+3, model_time=52.6]  0%|          | 49/96139 [01:45<57:34:43,  2.16s/it, avg_loss=371, data_time=53.2, grad_norm=6.03e+3, iter=48, loss=1.06e+3, model_time=52.6]  0%|          | 49/96139 [01:46<57:34:43,  2.16s/it, avg_loss=373, data_time=53.3, grad_norm=3.31e+4, iter=49, loss=577, model_time=53.3]      0%|          | 50/96139 [01:46<46:43:03,  1.75s/it, avg_loss=373, data_time=53.3, grad_norm=3.31e+4, iter=49, loss=577, model_time=53.3]  0%|          | 50/96139 [01:47<46:43:03,  1.75s/it, avg_loss=375, data_time=53.4, grad_norm=9.88e+4, iter=50, loss=565, model_time=54.1]  0%|          | 51/96139 [01:47<39:01:46,  1.46s/it, avg_loss=375, data_time=53.4, grad_norm=9.88e+4, iter=50, loss=565, model_time=54.1]  0%|          | 51/96139 [01:51<39:01:46,  1.46s/it, avg_loss=385, data_time=55.8, grad_norm=7.71e+5, iter=51, loss=1.37e+3, model_time=55.7]  0%|          | 52/96139 [01:51<60:30:07,  2.27s/it, avg_loss=385, data_time=55.8, grad_norm=7.71e+5, iter=51, loss=1.37e+3, model_time=55.7]  0%|          | 52/96139 [01:52<60:30:07,  2.27s/it, avg_loss=388, data_time=55.9, grad_norm=1.9e+7, iter=52, loss=624, model_time=56.6]       0%|          | 53/96139 [01:52<49:32:51,  1.86s/it, avg_loss=388, data_time=55.9, grad_norm=1.9e+7, iter=52, loss=624, model_time=56.6]  0%|          | 53/96139 [01:53<49:32:51,  1.86s/it, avg_loss=389, data_time=55.9, grad_norm=1.02e+7, iter=53, loss=552, model_time=57.3]  0%|          | 54/96139 [01:53<40:59:21,  1.54s/it, avg_loss=389, data_time=55.9, grad_norm=1.02e+7, iter=53, loss=552, model_time=57.3]  0%|          | 54/96139 [01:55<40:59:21,  1.54s/it, avg_loss=398, data_time=56, grad_norm=8.82e+12, iter=54, loss=1.28e+3, model_time=59]  0%|          | 55/96139 [01:55<43:06:29,  1.62s/it, avg_loss=398, data_time=56, grad_norm=8.82e+12, iter=54, loss=1.28e+3, model_time=59]  0%|          | 55/96139 [02:00<43:06:29,  1.62s/it, avg_loss=406, data_time=59.8, grad_norm=1.13e+10, iter=55, loss=1.17e+3, model_time=60.7]  0%|          | 56/96139 [02:00<73:08:06,  2.74s/it, avg_loss=406, data_time=59.8, grad_norm=1.13e+10, iter=55, loss=1.17e+3, model_time=60.7]  0%|          | 56/96139 [02:01<73:08:06,  2.74s/it, avg_loss=410, data_time=59.8, grad_norm=5.76e+11, iter=56, loss=806, model_time=61.7]      0%|          | 57/96139 [02:01<60:09:23,  2.25s/it, avg_loss=410, data_time=59.8, grad_norm=5.76e+11, iter=56, loss=806, model_time=61.7]  0%|          | 57/96139 [02:02<60:09:23,  2.25s/it, avg_loss=410, data_time=59.8, grad_norm=1.43e+5, iter=57, loss=436, model_time=62.3]   0%|          | 58/96139 [02:02<47:22:03,  1.77s/it, avg_loss=410, data_time=59.8, grad_norm=1.43e+5, iter=57, loss=436, model_time=62.3]  0%|          | 58/96139 [02:03<47:22:03,  1.77s/it, avg_loss=414, data_time=59.9, grad_norm=6.44e+8, iter=58, loss=787, model_time=63.5]  0%|          | 59/96139 [02:03<42:55:27,  1.61s/it, avg_loss=414, data_time=59.9, grad_norm=6.44e+8, iter=58, loss=787, model_time=63.5]  0%|          | 59/96139 [02:04<42:55:27,  1.61s/it, avg_loss=413, data_time=60.8, grad_norm=3.97e+6, iter=59, loss=317, model_time=64]    0%|          | 60/96139 [02:04<41:16:12,  1.55s/it, avg_loss=413, data_time=60.8, grad_norm=3.97e+6, iter=59, loss=317, model_time=64]sys:1: RuntimeWarning: Traceback of forward call that caused the error:
  File "train.py", line 298, in <module>
    run(config)
  File "train.py", line 212, in run
    run_state = run_epoch(model, optimizer, train_ldr, logger, *run_state)
  File "train.py", line 52, in run_epoch
    loss = model.loss(temp_batch)
  File "/home/dzubke/awni_speech/speech/speech/models/ctc_model_train.py", line 53, in loss
    out, rnn_args = self.forward_impl(x)
  File "/home/dzubke/awni_speech/speech/speech/models/ctc_model_train.py", line 45, in forward_impl
    x, rnn_args = self.encode(x, rnn_args)
  File "/home/dzubke/awni_speech/speech/speech/models/model.py", line 84, in encode
    x = self.conv(x)
  File "/home/dzubke/miniconda3/envs/awni_env36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/dzubke/miniconda3/envs/awni_env36/lib/python3.6/site-packages/torch/nn/modules/container.py", line 91, in forward
    input = module(input)
  File "/home/dzubke/miniconda3/envs/awni_env36/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/dzubke/miniconda3/envs/awni_env36/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py", line 66, in forward
    exponential_average_factor, self.eps)
  File "/home/dzubke/miniconda3/envs/awni_env36/lib/python3.6/site-packages/torch/nn/functional.py", line 1254, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled

Traceback (most recent call last):
  File "train.py", line 298, in <module>
    run(config)
  File "train.py", line 212, in run
    run_state = run_epoch(model, optimizer, train_ldr, logger, *run_state)
  File "train.py", line 56, in run_epoch
    loss.backward()
  File "/home/dzubke/miniconda3/envs/awni_env36/lib/python3.6/site-packages/torch/tensor.py", line 93, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/home/dzubke/miniconda3/envs/awni_env36/lib/python3.6/site-packages/torch/autograd/__init__.py", line 90, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: Function 'CudnnBatchNormBackward' returned nan values in its 0th output.
  0%|          | 60/96139 [02:13<59:29:53,  2.23s/it, avg_loss=413, data_time=60.8, grad_norm=3.97e+6, iter=59, loss=317, model_time=64]