seed: 2017
save_path: /home/dzubke/awni_speech/speech-lfs/examples/librispeech/models/ctc_models/20201006/ph2/
data:
    train_set: /mnt/disks/data_disk/home/dzubke/awni_speech/data/lib-ted-cv-spk/train_lib-ted-cv-speak-2M-2020-09-25_2020-10-05_dd.json
    dev_sets:
        speak: /mnt/disks/data_disk/home/dzubke/awni_speech/data/speak_test_data/2020-05-27/speak-test_2020-05-27_dd.json
        cv: /mnt/disks/data_disk/home/dzubke/awni_speech/data/common-voice/v5.1_2020-06-22/dev_dd.json
        libsp: /mnt/disks/data_disk/home/dzubke/awni_speech/data/LibriSpeech/dev-clean_dd.json
        ted: /mnt/disks/data_disk/home/dzubke/awni_speech/data/tedlium/TEDLIUM_release-3/dev_dd.json
    dev_set_save_reference: speak
    start_and_end: False
    num_workers: 4
logger:
    use_log: False
    log_file: logs/2020-10-06_large-model-mid-aug_lib-ted-cv-speak-2M-2020-09-25_2020-10-05.log
    debug_mode: False
preproc:
    preprocessor: log_spectrogram
    window_size: 32
    step_size: 16
    use_feature_normalize: True
    augment_from_normal: True
    tempo_gain_pitch_perturb: True
    tempo_gain_pitch_prob: 0.5
    tempo_range: [0.80, 1.20]
    gain_range: [-5, 5]
    pitch_range: [-250, 250]
    synthetic_gaussian_noise: True
    gauss_noise_prob: 0.5
    gauss_snr_db_range: [15, 50]
    background_noise: True
    background_noise_dir: /mnt/disks/data_disk/home/dzubke/awni_speech/data/noise/feed_to_model/
    background_noise_prob: 0.5
    background_noise_range: [0.0, 0.5]
    spec_augment: True
    spec_augment_prob: 0.5
    spec_augment_policy: 
        0: {W: 20, F: 30, m_F: 1, T: 18, m_T: 1}
        1: {W: 20, F: 15, m_F: 2, T: 9, m_T: 2} 
        2: {W: 20, F: 10, m_F: 3, T: 6, m_T: 3} 
optimizer:
    batch_size: 8
    run_state: [2962783, 33.56917]
    best_so_far: 0.202614
    start_epoch: 26
    epochs: 100
    learning_rate: 0.0005
    momentum: 0.5
    dampening: 0.0
    sched_gamma: 1.0 
    sched_step: 1
model: 
    class: this value is no longer used as train.py is hardcorded to use CTC_train
    multi_gpu: False
    dropout: 0.4
    blank_idx: last
    load_trained: True
    trained_path: ./examples/librispeech/models/ctc_models/20200925/ph3/model_state_dict_ckpt.pth
    remove_layers: []
    encoder: 
        conv:
            - [64, 11, 41, 1, 2, 0, 20]
            - [64, 11, 21, 1, 2, 0, 10]
            - [128, 11, 21, 1, 1, 0, 10]
        rnn: 
            type: LSTM
            dim: 1024
            bidirectional: False
            layers : 5
