seed: 2017
save_path: /home/dzubke/awni_speech/speech-lfs/examples/librispeech/models/ctc_models/20200908/ph7/
data:
    train_set: /mnt/disks/data_disk/home/dzubke/awni_speech/data/lib-ted-cv/train_lib-ted-cv-v5_2020-07-17_dd.json
    dev_sets:
        speak: /mnt/disks/data_disk/home/dzubke/awni_speech/data/speak_test_data/2020-05-27/speak-test_2020-05-27_dd.json
        cv: /mnt/disks/data_disk/home/dzubke/awni_speech/data/common-voice/v5.1_2020-06-22/dev_dd.json
        libsp: /mnt/disks/data_disk/home/dzubke/awni_speech/data/LibriSpeech/dev-clean_dd.json
        ted: /mnt/disks/data_disk/home/dzubke/awni_speech/data/tedlium/TEDLIUM_release-3/dev_dd.json
    dev_set_save_reference: speak
    start_and_end: false
    num_workers: 4
logger:
    use_log: False
    log_file: logs/2020-09-08_ph7_ddp_large-model-high-aug_lib-ted-cv.log
    debug_mode: false
preproc:
    preprocessor: log_spectrogram
    window_size: 32
    step_size: 16
    use_feature_normalize: True
    augment_from_normal: True
    tempo_gain_pitch_perturb: True
    tempo_gain_pitch_prob: 0.75
    tempo_range: [0.80, 1.20]
    gain_range: [-5, 5]
    pitch_range: [-250, 250]
    synthetic_gaussian_noise: True
    gauss_noise_prob: 0.75
    gauss_snr_db_range: [15, 50]
    background_noise: True
    background_noise_dir: /mnt/disks/data_disk/home/dzubke/awni_speech/data/noise/feed_to_model/
    background_noise_prob: 0.75
    background_noise_range: [0.0, 0.5]
    spec_augment: True
    spec_augment_prob: 0.75
    spec_augment_policy:
        0: {W: 20, F: 30, m_F: 1, T: 18, m_T: 1}
        1: {W: 20, F: 15, m_F: 2, T: 9, m_T: 2}
        2: {W: 20, F: 10, m_F: 3, T: 6, m_T: 3}
optimizer:
    batch_size: 16
    run_state: [1677344, 60.967165]
    best_so_far: 999
    start_epoch: 16
    epochs: 100
    learning_rate: 0.001
    momentum: 0.9
    dampening: 0.0
    sched_gamma: 1.0
    sched_step: 1
model: 
    class: this value is no longer used as train.py is hardcorded to use CTC_train
    dropout: 0.4
    load_trained: True
    trained_path: ./examples/librispeech/models/ctc_models/20200806/ph4/20200907/best_model_state_dict.pth
    remove_layers: []
    encoder: 
        conv:
            - [64, 11, 41, 1, 2, 0, 20]
            - [64, 11, 21, 1, 2, 0, 10]
            - [128, 11, 21, 1, 1, 0, 10]
        rnn: 
            type: LSTM
            dim: 1024
            bidirectional: False
            layers: 5
training: 
    multi_gpu: False
    distributed: True
    apex: False
    opt_level: 'O0'
    n_nodes: 1
    n_gpus: 8
    master_addr: '10.128.0.25'
    master_port: '8888'
