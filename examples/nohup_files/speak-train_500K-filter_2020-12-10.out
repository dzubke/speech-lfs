nohup: ignoring input
config:  {'full_json_path': '/home/dzubke/awni_speech/data/speak_train/train_data_trim_2020-09-22.json', 'metadata_tsv_path': '/home/dzubke/awni_speech/data/speak_train/speak-train-test_metadata_2020-09-22.tsv', 'filter_json_path': '/home/dzubke/awni_speech/data/speak_train/speak-train_500K_2020-12-10.json', 'dataset_name': 'SpeakTrain', 'dataset_size': 515000, 'constraints': {'lesson': 0.005, 'target_sentence': 0.0005, 'speaker': 0.0005}, 'disjoint_datasets': {'/home/dzubke/awni_speech/data/speak_test_data/2019-11-29/speak-test_2019-11-29.json': ('record', 'target_sentence', 'speaker'), '/home/dzubke/awni_speech/data/speak_test_data/2020-05-27/speak-test_2020-05-27.json': ('record', 'target_sentence', 'speaker')}}
constraints:  {'lesson': 2575, 'target_sentence': 257, 'speaker': 257}
header:  ['id', 'text', 'lessonId', 'lineId', 'uid', 'redWords_score', 'date']
all disjoint names:  dict_keys(['record', 'target_sentence', 'speaker'])
100000 examples written
200000 examples written
200000 examples written
300000 examples written
400000 examples written
400000 examples written
500000 examples written
500000 examples written
500000 examples written
500000 examples written
500000 examples written
500000 examples written
500000 examples written
500000 examples written
500000 examples written
500000 examples written
500000 examples written
500000 examples written
500000 examples written
500000 examples written
